\setchapterstyle{kao}
\setchapterpreamble[u]{\margintoc}
\chapter{Integration}
\labch{integration}

\section{Measurable functions}

If $\mathcal{N}$ is a $\sigma$-algebra on $Y$, $\{ f^{-1}(E): E \in \mathcal{N} \}$ is a $\sigma$-algebra on $X$.
To see this, we need to show that $\{ f^{-1}(E): E \in \mathcal{N} \}$ is closed under countable unions and complements.
For any $\{ f^{-1}(E_j) \}_{j=1}^{\infty}$ such that $f^{-1}(E_j) \in \{ f^{-1}(E): E \in \mathcal{N} \}$, 
\begin{align}
    \bigcup_{j=1}^{\infty} f^{-1}(E_j) & = \bigcup_{j=1}^{\infty} \{ x \in X: f(x) \in E_j \} \\
    & = \left\{ x \in X: f(x) \in \bigcup_{j=1}^{\infty} E_j \right\} \\
    & = f^{-1} \left( \bigcup_{j=1}^{\infty} E_j \right).
\end{align}
And since $\mathcal{N}$ is a $\sigma$-algebra on $Y$, then $E_j \in \mathcal{N}$ implies $\bigcup_{j=1}^{\infty} E_j \in \mathcal{N}$.
Thus, $f^{-1}(\bigcup_{j=1}^{\infty} E_j) \in \{ f^{-1}(E): E \in \mathcal{N} \}$.
For any $f^{-1}(E) \in \{ f^{-1}(E): E \in \mathcal{N} \}$, 
\begin{align}
    \left( f^{-1}(E) \right)^c & = X \setminus \{ x \in X: f(x) \in E \} \\
    & = \{ x \in X: f(x) \in E^c \} \\
    &= f^{-1}(E^c).
\end{align}
Again, since $\mathcal{N}$ is a $\sigma$-algebra on $Y$, $E \in \mathcal{N}$ implies $E^c \in \mathcal{N}$.
Thus, $f^{-1}(E^c) \in \{ f^{-1}(E): E \in \mathcal{N} \}$


\begin{definition}[Measurable function]
    If $(X, \mathcal{M})$ and $(Y, \mathcal{N})$ are measurable spaces, a mapping $f: X \to Y$ is called $(\mathcal{M}, \mathcal{N})$-measurable, or just measurable when $\mathcal{M}$ and $\mathcal{N}$ are understood, if $f^{-1}(E) \in \mathcal{M}$ for all $E \in \mathcal{N}$.
\end{definition}

The composition of measurable functions is measurable.
If $f: X \to Y$ is $(\mathcal{M}, \mathcal{N})$-measurable and $g: Y \to Z$ is $(\mathcal{N}, \mathcal{O})$-measurable, then $g \circ f$ is $(\mathcal{M}, \mathcal{O})$-measurable.

\begin{proposition}
    \labprop{measurable_function_E}
    If $\mathcal{N}$ is generated by $\mathcal{E}$, then $f: X \to Y$ is $(\mathcal{M}, \mathcal{N})$-measurable iff $f^{-1}(E) \in \mathcal{M}$ for all $E \in \mathcal{E}$. 
\end{proposition}

\begin{proof}
    The only if part is trivial since $\mathcal{E} \subset \mathcal{N}$.
    For the converse, observe that $\{ E \subset Y: f^{-1}(E) \in \mathcal{M} \}$ is a $\sigma$-algebra that contains $\mathcal{E}$.
    It therefore contains $\mathcal{N}$.
\end{proof}

\begin{definition}
    If $(X, \mathcal{M})$ is a measurable space, a real- or complex-valued function $f$ on $X$ will be called $\mathcal{M}$-measurable or just measurable if it is $(\mathcal{M}, \mathcal{B}_{\R})$- or $(\mathcal{M}, \mathcal{B}_{\C})$-measurable.
\end{definition}

\begin{corollary}
    \labcorollary{continuous_function_Borel_measurable}
    If $X$ and $Y$ are metric (or topological) spaces, every continuous $f:X \to Y$ is $(\mathcal{B}_{X}, \mathcal{B}_{Y})$-measurbale.
\end{corollary}

\begin{proof}
    By \refprop{continuous_open}, $f$ is continuous iff $f^{-1}(U)$ is open in $X$ for every open $U \subset Y$.
    $\mathcal{B}_{Y}$ is generated by open sets, and $f^{-1}(U)$ is open and hence belongs in $\mathcal{B}_{X}$ for all open $U \subset Y$.
\end{proof}

\begin{definition}[Lebesgue measurable]
    \labdef{Lebesgue_measurable}
    $f: \R \to \R$ is Lebesgue measurable if it is $(\mathcal{L}, \mathcal{B}_{\R})$-measurable; likewise for $f:\R \to \C$.
\end{definition}

\begin{definition}[Borel measurable]
    \labdef{Borel_measurable}
    $f: \R \to \R$ is Borel measurable if it is $(\mathcal{B}_{\R}, \mathcal{B}_{\R})$-measurable; likewise for $f:\R \to \C$.
\end{definition}

\begin{remark}
    If $f, g$ are Lebesgue measurable, it does not follow that $f \circ g$ is Lebesgue measurable, even if $g$ is assumed to be continuous.
\end{remark}

\begin{remark}
    If $f$ is Borel measurable, then $f \circ g$ is Lebesgue or Borel measurable whenever $g$ is.
\end{remark}

\begin{proposition}
    \labprop{M_measurable}
    If $(X, \mathcal{M})$ is a measurable space and $f: X \to \R$, the following are equivalent:
    \begin{enumerate}
        \item $f$ is $\mathcal{M}$-measurable.
        \item $f^{-1}((a, \infty)) \in \mathcal{M}$ for all $a \in \R$.
        \item $f^{-1}([a, \infty)) \in \mathcal{M}$ for all $a \in \R$.
        \item $f^{-1}((-\infty, a)) \in \mathcal{M}$ for all $a \in \R$.
        \item $f^{-1}((-\infty, a]) \in \mathcal{M}$ for all $a \in \R$.
    \end{enumerate}
\end{proposition}

\begin{proof}
    By \refprop{generate_Borel_sigma_algebra}, $(a, \infty)$ (or $[a, \infty)$, or $(-\infty, a)$, or $(-\infty, a]$) can generate $\mathcal{B}_{\R}$.
    Thus, $f$ is $\mathcal{M}$-measurable iff $f^{-1}(E) \in \mathcal{M}$ for all $E \in \{ (a, \infty): a \in \R \}$ by \refprop{measurable_function_E}.
\end{proof}

\begin{definition}
    If $(X, \mathcal{M})$ is a measurable space and $f$ is a function on $X$, and $E \in \mathcal{M}$, $f$ is measurable on $E$ if $f^{-1}(B) \cap E \in \mathcal{M}$ for all Borel sets $B$.
    Equivalently, $f|E$ is $\mathcal{M}_E$-measurable, where $\mathcal{M}_E = \{ F \cap E: F \in \mathcal{M} \}$.
\end{definition}

\begin{proposition}
    If $X = A \cup B$ where $A, B \in \mathcal{M}$, a function $f$ on $X$ is measurable iff $f$ is measurable on $A$ and on $B$.
\end{proposition}

By \refcorollary{continuous_function_Borel_measurable}, continuous functions are measurable.
In addition, monotonic functions are measurable.

\begin{proposition}
    If $f: \R \to \R$ is monotone, then $f$ is Borel measurable.
\end{proposition}

\begin{proof}
    If we can show that for all $a \in \R$, $f^{-1}([a, \infty))$ is an interval, then $f$ must be Borel measurable.
    Without loss of generality, assume $f$ is monotonic increasing.
    Then for an arbitrary $a \in \R$, $x \in f^{-1}([a, \infty))$, and $y \in [x, \infty)$, $a \le f(x) \le f(y)$.
    Thus $y \in  f^{-1}([a, \infty))$.
    Therefore $f^{-1}([a, \infty))$ is indeed an interval, and hence Borel measurable.
    So, $f$ is Borel measurable since this is true for all $a \in \R$.
\end{proof}

\begin{proposition}
    \labprop{product_measurable_function}
    Let $(X, \mathcal{M})$ and $(Y_{\alpha}, \mathcal{N}_{\alpha})$ ($\alpha \in A$) be measurable spaces, $Y = \prod_{\alpha \in A} Y_{\alpha}$, $\mathcal{N} = \prod_{\alpha \in A} \mathcal{N}_{\alpha}$, and $\pi_{\alpha}: Y \to Y_{\alpha}$ the coordinate maps. Then $f: X \to Y$ is $(\mathcal{M}, \mathcal{N})$-measurable iff $f_{\alpha} = \pi_{\alpha} \circ f$ is $(\mathcal{M}, \mathcal{N}_{\alpha})$-measurable for all $\alpha \in A$.
\end{proposition}

\begin{proof}
    If $f$ is measurable, so is each $f_{\alpha}$ since the composition of measurable maps\sidenote{$\pi_{\alpha}$ is $(\mathcal{N}, \mathcal{N}_{\alpha})$-measurable.} is measurable.
    Conversely, if each $f_{\alpha}$ is measurable, then for all $E_{\alpha} \in \mathcal{N}_{\alpha}$, $f^{-1}(\pi_{\alpha}^{-1}(E_{\alpha})) = f_{\alpha}^{-1}(E_{\alpha}) \in \mathcal{M}$, whence $f$ is measurable by \refprop{measurable_function_E}.
\end{proof}

\begin{corollary}
    A function $f: X \to \C$ is $\mathcal{M}$-measurable iff $\Re(f)$ and $\Im(f)$ are $\mathcal{M}$-measurable.
\end{corollary}

\begin{proof}
    This follows since $\mathcal{B}_{\C} = \mathcal{B}_{\R^2} = \mathcal{B}_{\R} \otimes \mathcal{B}_{\R}$. 
\end{proof}

\begin{proposition}
    \labprop{add_mul_measurable}
    If $f,g$ are $\mathcal{M}$-measurable, then so are $f+g$ and $f g$.
\end{proposition}

\begin{proof}
    Define $F: X \to \C \times \C$, $\phi: \C \times \C \to \C$, and $\psi: \C \times \C \to \C$ by $F(x) = (f(x), g(x))$, $\phi(z, w) = z + w$, $\psi(z, w) = z w$.
    Since $\mathcal{B}_{\C \times \C} = \mathcal{B}_{\C} \otimes \mathcal{B}_{\C}$ by \refprop{product_Borel_sigma_algebra}, $F$ is $(\mathcal{M}, \mathcal{B}_{\C \times \C})$-measurable by \refprop{product_measurable_function}, whereas $\phi$ and $\psi$ are $(\mathcal{B}_{\C \times \C}, \mathcal{B}_{\C})$-measurable by \refcorollary{continuous_function_Borel_measurable}.
    Thus $f+g = \phi \circ F$ and $fg = \psi \circ F$ are $\mathcal{M}$-measurable.
\end{proof}

\refprop{add_mul_measurable} remains valid for $\bar{\R}$-valued functions provided one takes a litte care with the indeterminate expressions $\infty - \infty$ and $0 \cdot \infty$.

\begin{corollary}
    Suppose $f,g: X \to \bar{\R}$ are measurable.
    Fix $a \in \bar{\R}$ and define
    \begin{align}
        (f+g)(x) = \begin{cases}
            a, & \text{ if } f(x) = -g(x) = \pm \infty, \\
            f(x) + g(x), & \text{ otherwise.}
        \end{cases}
    \end{align}
    Then $f+g$ is measurable.
    And $fg$ is measurable where $0 \cdot (\pm \infty) = 0$.
\end{corollary}

\begin{proof}
    
\end{proof}

\begin{proposition}
    If $\{f_j\}$ is a sequence of $\bar{\R}$-valued measurable functions on $(X, \mathcal{M})$, then the functions $\sup_j f_j(x)$, $\inf_j f_j(x)$, $\limsup_{j \to \infty} f_j(x)$, and $\liminf_{j \to \infty} f_j(x)$ are all measurable.
    If $f(x) = \lim_{j \to \infty}$ exists for every $x \in X$, then $f$ is measurable.
\end{proposition}

\begin{proof}
    We have $(\sup_j f_j)^{-1}((a, \infty]) = \bigcup_{j}f_{j}^{-1}((a, \infty])$ and $(\inf_j f_j)^{-1}([-\infty, a)) = \bigcup_{j}f_{j}^{-1}([-\infty, a))$, so $\sup_j f_j(x)$ and $\inf_j f_j(x)$ are measurable by \refprop{M_measurable}.

    More generally, if $h_k(x) = \sup_{j \ge k} f_j(x)$ then $h_k$ is measurable for each $k$, so $\limsup_{j \to \infty} f_j = \inf_k h_k$ is measurbale, and likewise for $\liminf_{j \to \infty} f_j$.

    Finally, if $f$ exists, then $f = \limsup_{j \to \infty} f_j = \liminf_{j \to \infty} f_j$, so $f$ is measurable.
\end{proof}

\begin{corollary}
    \labcorollary{max_min_measurable}
    If $f, g: X \to \C$ are $\mathcal{M}$-measurable, then so are functions $\max(f, g)$ and $\min(f, g)$.
\end{corollary}

\begin{corollary}
    \labcorollary{lim_measurable}
    If $\{ f_j \}$ is a sequence of complex-valued measurable functions and $f(x) = \lim_{j \to \infty} f_j(x)$ exists for all $x$, then $f$ is measurable.
\end{corollary}

\begin{definition}
    If $f: X \to \bar{\R}$, we define the positive and negative parts of $f$ to be $f^{+}(x) = \max(f(x), 0)$ and $f^{-}(x) = \min(f(x), 0)$, respectively. 
\end{definition}

Clearly, $f = f^{+} - f^{-}$.
And if $f$ is measurable, so are $f^{+}$ and $f^{-}$.

\begin{definition}[Polar decomposition]
    If $f: X \to \C$, the polar decomposition of $f$ is:
    \begin{align}
        f = (\sgn f) |f|,
    \end{align}
    where 
    \begin{align}
        \sgn z = \begin{cases}
            z / |z|, & \text{ if } z \ne 0, \\
            0, & \text{ if } z = 0.
        \end{cases}
    \end{align}
\end{definition}

Again, if $f$ is measurable, so are $\sgn f$ and $|f|$.
Indeed, $z \mapsto |z|$ is continuous on $\C$ and hence measurable by \refcorollary{continuous_function_Borel_measurable}.
And $z \mapsto \sgn z$ is continuous except at the origin.
Thus if $U \subset \C$ is open, $\sgn^{-1}(U)$ is either open or of the form $V\cup\{0\}$ where $V$ is open, so $sgn$ is measurable.
Therefore, $|f| = |\cdot| \circ f$ and $\sgn f = \sgn \circ f$ are measurable.

\begin{definition}
    Suppose $(X, \mathcal{M})$ is a measurable space.
    If $E \subset X$, the characteristic function $\chi_E$ of $E$ (sometimes called the indicator function of $E$ and denoted by $\mathbf{1}_E$) is defined by
    \begin{align}
        \chi_E(X) = \begin{cases}
            1, & \text{ if } x \in E, \\
            0, & \text{ if } x \notin E.
        \end{cases}
    \end{align}
\end{definition}

It is easy to check that $\chi_E$ is measurable iff $E \in \mathcal{M}$.

\begin{definition}
    A simple function on $X$ is finite linear combination, with complex coefficients\sidenote{We do not allow simple function to assume the values $\pm \infty$.}, of characteristic functions of sets in $\mathcal{M}$.
\end{definition}

\begin{theorem}
    \labthm{approximate_by_simple_functions}
    Let $(X, \mathcal{M})$ be a measurable space.
    \begin{enumerate}
        \item If $f: X \to [0, \infty]$ is measurable, there is a sequence $\{ \phi_n \}$ of simple functions such that $0 \le \phi_1 \le \phi_2 \le \cdots \le f$, $\phi_n \to f$ pointwise, and $\phi_n \to f$ uniformly on any set on which $f$ is bounded.
        \item If $f: X \to \C$ is measurable, there is a sequence $\{ \phi_n \}$ of simple functions such that $0 \le |\phi_1| \le |\phi_2| \le \cdots \le |f|$, $\phi_n \to f$ pointwise, and $\phi_n \to f$ uniformly on any set on which $f$ is bounded.
    \end{enumerate}
\end{theorem}

\begin{proof}
    For $n=0, 1, \dots$ and $0 \le k \le 2^{2n}-1$, let
    \begin{align}
        E_{n}^{k} & = f^{-1}((k 2^{-n}, (k+1) 2^{-n}]), \\
        F_{n} & = f^{-1}((2^n, \infty]), \\
        \phi_{n} & = \left( \sum_{k=0}^{2^{2n}-1} k 2^{-n} \chi_{E_{n}^{k}} \right) + 2^{n} \chi_{F_{n}}.
    \end{align}
    The range of $f$ is partitioned by $2^{2n}$ intervals indexed by $k$.
    It is easy to check that $\phi_{n} \le \phi_{n+1}$ for all $n$, and $0 \le f - \phi_{n} \le 2^{-n}$ on the set where $f \le 2^{n}$.
    The result therefore follows.

    If $f = g + i h$, we can apply part 1 to the positive and negative parts of $g$ and $h$, obtaining the sequences $\psi_{n}^{+}$, $\psi_{n}^{-}$, $\zeta_{n}^{+}$, $\zeta_{n}^{-}$ of nonnegative simple functions that increase to $g^+$, $g^-$, $h^+$, $h^-$.
    Let $\phi_n = (\psi_{n}^{+} - \psi_{n}^{-}) + i (\zeta_{n}^{+} - \zeta_{n}^{-})$.
    Then it is easy to check that $|\phi_{n}| \le |\phi_{n+1}|$ for all $n$, and $0 \le |f - \phi_{n}| \le 4 \cdot 2^{-n}$ on the set where $|f| \le 4 \cdot 2^{n}$\sidenote{Because $\psi_{n}^{+} \le \psi_{n+1}^{+}$ for all $n$, and $0 \le g^+ - \psi_{n}^{+} \le 2^{-n}$ on the set where $g^+ \le 2^{n}$ and likewise for $\psi_{n}^{-}$, $\zeta_{n}^{+}$, and $\zeta_{n}^{-}$.}.
\end{proof}

If $\mu$ is a measure on $(X, \mathcal{M})$, we may wish to except $\mu$-null sets from consideration in studying measurable functions.
In this respect, it would be easier if $\mu$ is complete. 

\begin{proposition}
    \labprop{complete_measure_measurable_function}
    The following implications are valid iff the measure $\mu$ is complete:
    \begin{enumerate}
        \item If $f$ is measurable and $f = g$ $\mu$-almost everywhere, then $g$ is measurable.
        \item If $f_n$ is measurable for $n \in \N$ and $f_n \to f$ $\mu$-almost everywhere, then $f$ is measurable.
    \end{enumerate}
\end{proposition}

\begin{proof}
    Suppose that $\mu$ is complete.
    For any Borel set $B \in \mathcal{B}_{\C}$, $g^{-1}(B) = (f^{-1}(B) \setminus \{f \ne g\}) \cup (g^{-1}(B) \cap \{f \ne g\})$.
    And since $\mu$ is complete, $\mathcal{M} \ni (g^{-1}(B) \cap \{f \ne g\}) \subset \{f \ne g\} \in \mathcal{M}$.
    Thus $g^{-1}(B) \in \mathcal{M}$, so $g$ is measurable.
    Let $\hat{f} = \limsup f_n$.
    We have $\hat{f} = f$ $\mu$-almost everywhere.

    Suppose that $\mu$ is not complete. 
    Then there is a measurable set $E$ with $\mu(E) = 0$ and a set $F \subset E$ such that $F \notin \mathcal{M}$.
    Then $\chi_{F}$ is not measurable and $\chi_{F} = 0$ $\mu$-almost everywhere.
    Similarly, let $f_n = 0$ and $f=\chi_{F}$.
\end{proof}

Intuitively, since $f^{-1}(E) \triangle g^{-1}(E) \subset \{ f \ne g \}$, $f^{-1}(E)$ and $g^{-1}(E)$ differ by a subset of $\mu$-null set.
Thus the completeness of $\mu$ will make $g^{-1}(E) \in \mathcal{M}$ whenever $f^{-1}(E) \in \mathcal{M}$.

\begin{proposition}
    \labprop{completion_measurable_function}
    Let $(X, \mathcal{M}, \mu)$ be a measurable space and $(X, \bar{\mathcal{M}}, \bar{\mu})$ be its completion.
    If $f$ is an $\bar{\mathcal{M}}$-measurable function on X, there is an $\mathcal{M}$-measurable function $g$ such that $f = g$ $\bar{\mu}$-almost everywhere.
\end{proposition}

\begin{proof}
    This is obvious from the definition of $\bar{\mu}$ if $f = \chi_E$ where $E \in \bar{\mathcal{M}}$, and hence if $f$ is $\bar{\mathcal{M}}$-measurable simple function.
    For the general case, choose a sequence $\{\phi_n\}$ of $\bar{\mathcal{M}}$-measurable simple functions that converge pointwise to $f$ according to .
    And for each $n$, let $\psi_n$ be an $\mathcal{M}$-measurable simple functions with $\psi_n = \phi_n$ except on a set $E_n \in \bar{\mathcal{M}}$ with $\bar{\mu}(E_n) = 0$.
    Choose $N \in \mathcal{M}$ such that $\mu(N) = 0$ and $N \supset \bigcup_{n=1}^{\infty} E_n$, and set $g = \lim_n \chi_{X \setminus N} \psi_n$.
    Then $g$ is $\mathcal{M}$-measurable by \refcorollary{lim_measurable}, and $g = f$ on $N^c$.
\end{proof}

\section{Integration of nonnegative functions}

\begin{definition}
    If $\phi$ is a simple function in $L^+$ with standard representation $\phi = \sum_{j=1}^{n} a_j \chi_{E_j}$, we define the integral of simple function $\phi$ with respect to $\mu$ by
    \begin{align}
        \int \phi \dd \mu = \sum_{j=1}^{n} a_j \mu(E_j).
    \end{align}
\end{definition}

Note that $\int \phi \dd \mu$ may equal $\infty$.
When there is no danger of confusion, we may also write $\int \phi$ for $\int \phi \dd \mu$.

To summarize, $\int_{A} \phi \dd \mu = \int_{A} \phi = \int_{A} \phi(x) \dd \mu(x) = \int \phi \chi_{A} \dd \mu$ and $\int \phi = \int_{X} \phi$.

\begin{proposition}[Properties for integrals of simple functions]
    \labprop{properties_integrals_simple_function}
    Let $\phi$ and $\psi$ be simple function in $L^+$.
    \begin{enumerate}
        \item $\int c \phi = c \int \phi$ for $c > 0$.
        \item $\int (\phi + \psi) = \int \phi + \int \psi$.
        \item If $\phi \le \psi$, then $\int \phi \le \int \psi$.
        \item The map $A \mapsto \int_{A} \dd \mu$ is a measure on $\mathcal{M}$.
    \end{enumerate}
\end{proposition}

\begin{proof}
    TODO
\end{proof}

After defining integrals for simple functions and examining its crucial properties, we now extend the integral to all functions in $L^+$.

\begin{definition}
    For any function $f \in L^+$, we define its integral by
    \begin{align}
        \int f \dd \mu = \sup \left\{ \int \phi \dd \mu: 0 \le \phi \le f, \phi \text{ is simple} \right\}.
    \end{align}
\end{definition}

The properties for integrals of simple functions can be extended to function in $L^+$.

The next step is to establish one of the fundamental convergence theorems.

\begin{theorem}[The monotone convergence theorem]
    \labthm{monotone_convergence_theorem}
    If $\{ f_n \}$ is a sequence in $L^+$ such that $f_j \le f_{j+1}$ for all $j$, and $f = \lim_{n \to \infty} f_n = \sup_{n} f_n$, then $\int f = \lim_{n \to \infty} \int f_n$.
\end{theorem}

\begin{proof}
    $\{ \int f_n \}$ is an increasing sequence of numbers, so its limit exists (possibly $\infty$). 
    Moreover, $\int f_n \le \int f$ for all $n$, so $\lim_{n} \int f_n \le \int f$.

    To establish the reverse inequality, fix $\alpha \int (0, 1)$, let $\phi$ be a simple function with $0 \le \phi \le f$, and let $E_n = \{ x: f_n(x) \ge \alpha \phi(x) \}$.
    Then $\{ E_n \}$ is an increasing sequence of measurable sets whose union is $X$, and we have $\int f_n \ge \int_{E_n} f_n \ge \alpha \int_{E_n} \phi$.
    By \refthm{properties_measure} and \refprop{properties_integrals_simple_function}, $\lim_{n} \int_{E_n} \phi = \int \phi$, and hence $\lim_n \int f_n \ge \alpha \int \phi$.
    Since this is true for all $\alpha \int (0, 1)$, it remains true for $\alpha =1$, and taking the supremum over all simple $\phi \le f$, we obtain $\lim_n \int f_n \ge \int f$.
\end{proof}

\begin{theorem}
    \labthm{infinite_add_measurable_function}
    If $\{ f_n \}$ is a finite or infinite sequence in $L^+$ and $f = \sum_{n} f_n$, then $\int f = \sum \int f_n$.
\end{theorem}

\begin{proof}
    First, consider two functions $f_1$ and $f_2$ in $L^+$.
    By \refthm{approximate_by_simple_functions}, we can find sequences $\{ \phi_j \}$ and $\{ \psi_j \}$ of nonnegative simple functions that increase to $f_1$ and $f_2$.
    Then $\{ \phi_j + \psi_j \}$ increases to $f_1 + f_2$, so by \refthm{monotone_convergence_theorem} and \refprop{properties_integrals_simple_function}, 
    \begin{align}
        \int (f_1 + f_2) = \lim \int (\phi_j + \psi_j) = \lim \int \phi_j + \lim \int \psi_j = \int f_1 + \int f_2.
    \end{align}
    Hence by induction, $\int \sum_{n=1}^{N} f_n = \sum_{n=1}^{N} \int f_n$ for finitely many $N$.
    Letting $N \to \infty$ and applying \refthm{monotone_convergence_theorem} again, we obtain $\int \sum_{n=1}^{\infty} f_n = \sum_{n=1}^{\infty} \int f_n$.
\end{proof}

\begin{proposition}
    \labprop{0_almost_everywhere}
    If $f \in L^+$, then $\int f = 0$ iff $f = 0$ almost everywhere.
\end{proposition}

\begin{proof}
    This is obvious if $f$ is simple.
    If $f = \sum_{j=1}^{n} a_j \chi_{E_j}$ with $a_j \ge 0$, then $\int f = 0$ iff for each $j$ either $a_j = 0$ or $\mu(E_j) = 0$.
    
    In general if $f=0$ almost everywhere and $\phi$ is simple with $0 \le \phi \le f$, then $\phi = 0$ almost everywhere, hence $\int f = \sup_{\phi \le f} \int \phi = 0$.
    On the other hand, $\{ x: f(x) > 0 \} = \bigcup_{n=1}^{\infty} E_n$ where $E_n = \{ x: f(x) > \frac{1}{n} \}$, so if it is false that $f=0$ almost everywhere, we must have $\mu(E_n) > 0$ for some $n$.
    But then $f > \frac{\chi_{E_n}}{n}$ and consequently $\int f \ge \frac{\mu(E_n)}{n} > 0$. 
\end{proof}

This implies if $f, g \in L^+$, then $\int f = \int g$ iff $f = g$ almost everywhere.

\begin{corollary}
    If $\{ f_n \} \subset L^+$, $f \in L^+$, and $f_n(x)$ increases to $f(x)$ for almost everywhere $x$, then $\int f = \lim \int f_n$.
\end{corollary}

\begin{proof}
    If $f_n(X)$ increases to $f(X)$ for $x \in E$ where $\mu(E^c) = 0$, then $f - f \chi_{E} = 0$ almost everywhere and $f_n - f_n \chi_{E} = 0$ almost everywhere, so by \refthm{monotone_convergence_theorem}, $\int f = \int f \chi_E = \lim_n \int f_n \chi_E = \lim_n \int f_n$.
\end{proof}

\begin{lemma}[Fatou's Lemma]
    \lablemma{Fatou_lemma}
    If $\{ f_n \}$ is any sequence in $L^+$, then 
    \begin{align}
        \int (\liminf f_n) \le \liminf \int f_n.
    \end{align}
\end{lemma}

\begin{proof}
    For each $k \ge 1$, we have $\inf_{n \ge k} f_n \le f_j$ for $j \ge k$, hence 
    $\int \inf_{n \ge k} f_n \le \int f_j$ for $j \ge k$, and hence $\int \inf_{n \ge k} f_n \le \inf_{j \ge k} \int f_j$.
    Now let $k \to \infty$ and apply \refthm{monotone_convergence_theorem}:
    \begin{align}
        \int (\liminf f_n) = \lim_{k \to \infty} \int (\inf_{n \ge k} f_n) \le \liminf \int f_n.
    \end{align}
\end{proof}

\begin{corollary}
    If $\{ f_n \} \subset L^+$, $f \in L^+$, and $f_n(x) \to f$ almost everywhere, then $\int f \le \liminf \int f_n$.
\end{corollary}

\begin{proposition}
    \labprop{infinite_null_set}
    If $f \in L^+$ and $\int f < \infty$, then $\{ x: f(x) = \infty \}$ is a null set and $\{ x: f(x) > 0 \}$ is $\sigma$-finite. 
\end{proposition}

\begin{proof}
    First, suppose $\{ x : f(x) = \infty \}$ is not a null set.
    So $\mu(\{ x : f(x) = \infty \}) > 0$. 
    Let us construct a simple function $\phi \in L^+$ by
    \begin{align}
        \phi(x) = \begin{cases}
            \infty, & \text{ if } f(x) = \infty, \\
            0, & \text{ if } f(x) < \infty.
        \end{cases}
    \end{align}
    Then $0 \le \phi \le f$, and $\int f \ge \int \phi = \infty \cdot \mu(\{ x : f(x) = \infty \}) = \infty$ which contradicts to $\int f < \infty$.
    Therefore, $\{ x : f(x) = \infty \}$ is a null set.

    Second, suppose $\{ x: f(x) > 0 \}$ is not $\sigma$-finite which means there exists $\mu(E_j) = \infty$ for some $j$ with $\{ x: f(x) > 0 \} = \bigcup_{j=1}^{\infty} E_j$ for whatever $\{ E_j \}$.
    Take $E_j = \{ x: f(x) > 1/j \}$ and $\mu(E_j) = \infty$.
    Let us again construct a simple function $\psi \in L^+$ by
    \begin{align}
        \psi(x) = \begin{cases}
            1/j, & \text{ if } x \in E_j, \\
            0, & \text{ if } x \notin E_j.
        \end{cases}
    \end{align} 
    Then $0 \le \psi \le f$, and $\int f \ge \int \psi = (1/j) \cdot \mu(\{ x : f(x) > 1/j \}) = \infty$ which contradicts to $\int f < \infty$.
    Therefore, $\{ x: f(x) > 0 \}$ is $\sigma$-finite.
\end{proof}

\section{Integration of complex functions}

We continue to work on a fixed measure space $(X, \mathcal{M}, \mu)$.


\begin{definition}
    We say that a real-valued function $f$ is integrable if $\int f^+$ and $\int f^-$ are both finite.
\end{definition}

\begin{proposition}
    The set of integrable real-valued functions on $X$ is a real vector space, and the integral is a linear function on it. 
\end{proposition}

\begin{proof}
    TODO
\end{proof}

Since $|f| \le |\Re f| + |\Im f| \le 2 |f|$, $f$ is integrable iff $\Re f$ and $\Im f$ are both integrable, and in this case we define $\int f = \int \Re f + i \int \Im f$. 

\begin{proposition}
    \labprop{abs_int_le_int_abs}
    If $f \in L'$, then $|\int f| \le \int |f|$.
\end{proposition}

\begin{proof}
    This is trivial if $\int f = 0$ and almost trivial if $f$ is real, since
    \begin{align}
        \left| \int f \right| = \left| \int f^{+} - \int f^{-} \right| \le \int f^{+} + \int f^{-} = \int |f|.
    \end{align}
    If $f$ is complex-valued and $\int f \ne 0$, let $\alpha = \sgn(\int f)$.
    Then $|\int f| = \alpha \int f = \int \alpha f$.
    In particular, $\int \alpha f$ is real, so
    \begin{align}
        \left| \int f \right| = \Re \int \alpha f = \int \Re(\alpha f) \le \int |\Re(\alpha f)| \le \int |\alpha f| = \int |f|.
    \end{align}
\end{proof}

\begin{proposition}
    If $f \in \int L'$, then $\{ x: f(x) \ne 0 \}$ is $\sigma$-finite.
\end{proposition}

\begin{proof}
    Apply \refprop{infinite_null_set} to $|f|$.
\end{proof}

\begin{proposition}
    If $f, g \in L'$, then $\int_E f = \int_E g$ for all $E \in \mathcal{M}$ iff $\int |f-g| = 0$ iff $f=g$ almost everywhere.
\end{proposition}

\begin{proof}
    The second equivalence follows from \refprop{0_almost_everywhere}.

    If $\int |f-g| =0$, then by \refprop{abs_int_le_int_abs}, for any $E \in \mathcal{M}$,
    \begin{align}
        \left| \int_E f - \int_E g \right| \le \int_E |f-g| \le \int |f-g|, 
    \end{align}
    so that $\int_E f = \int_E g$.
    On the other hand, if $u = \Re(f-g)$, $v = \Im(f-g)$, and it is false that $f=g$ almost everywhere, then at least one of $u^+$, $u^-$, $v^+$, and $v^-$ must be nonzero on a set of positive measure.
    If, say, $E = \{ x: u^+(x) > 0 \}$ has positive measure, then $\Re(\int_E f - \int_E g) = \int_E u^+ >0$ since $u^- = 0$ on $E$.
    And likewise in the other cases.
\end{proof}

This proposition shows that for the purposes of integration it makes no difference if we alter functions on null sets.

\begin{definition}
    $L^1$ is the set of equivalence classes of almost everywhere definited integrable functions on $X$.
\end{definition}

\begin{theorem}[The Dominated Convergence Theorem]
    \labthm{dominated_convergence}
    Let $\{ f_n \}$ be a sequence in $L^1$ such that $f_n \to f$ and there exists a nonnegative $g \in L^1$ such that $|f_n| \le g$ almost everywhere for all $n$. Then $f \in L^1$ and $\int f = \lim_{n \to \infty} \int f_n$.
\end{theorem}

\begin{proof}
    $f$ is measurable by \refprop{complete_measure_measurable_function} and \refprop{completion_measurable_function}, and since $|f| \le g$ almost everywhere, we have $f \in L^1$.
    By taking real and imaginary parts it suffices to assume that $f_n$ and $f$ are real-valued, in which case we have $g+f_n \ge 0$ almost everywhere and $g - f_n \ge 0$ almost everywhere.
    Thus by \reflemma{Fatou_lemma},
    \begin{align}
        \int g + \int f \le \liminf (g+f_n) = \int g + \liminf \int f_n, \\
        \int g - \int f \le \liminf (g-f_n) = \int g - \limsup \int f_n.
    \end{align}
    Therefore, $\liminf \int f_n \ge \int f \ge \limsup \int f_n$, and the result follows.
\end{proof}

\begin{theorem}
    \labthm{add_L1_measurable_function}
    Suppose $\{ f_j \}$ is a sequence in $L^1$ such that $\sum_{j=1}^{\infty} \int |f_j| < \infty$.
    Then $\sum_{j=1}^{\infty} f_j$ converges almost everywhere to a function in $L^1$, and $\int \sum_{j=1}^{\infty} f_j = \sum_{j=1}^{\infty} \int f_j$.
\end{theorem}

\begin{proof}
    By \refthm{infinite_add_measurable_function}, as $\{|f_j|\}$ is a sequence in $L^+$, $\int \sum_{j=1}^{\infty} |f_j| = \sum_{j=1}^{\infty} \int |f_j| < \infty$, so the function $g = \sum_{j=1}^{\infty} |f_j|$ is in $L^+$. 
    In particular, by \refprop{infinite_null_set}, $\{ x: g(x) = \infty \}$ is a null set, so $g$ is finite for almost everywhere $x$, and for each such $x$ the series $\sum_{j=1}^{\infty} f_j(x)$ converges.
    Moreover, $|\sum_{j=1}^{n} f_j| \le g$ for all $n$, so we can apply \refthm{dominated_convergence} to the sequence of partial sums to obtain $\int \sum_{j=1}^{\infty} f_j = \sum_{j=1}^{\infty} \int f_j$.
\end{proof}

\begin{theorem}
    \labthm{approximate_in_L1}
    If $f \in L^{1} (\mu)$ and $\epsilon > 0$, there is an integrable simple function $\phi = \sum a_j \chi_{E_j}$ such that $\int |f - \phi| \dd \mu < \epsilon$.
    If $\mu$ is a Lebesgue-Stieltjes measure on $\R$, the sets $E_j$ in the definition of $\phi$ can be taken to be finite unions of open intervals;
    moreover, there is a continuous function $g$ that vanishes outside a bounded interval such that $\int |f - g| \dd \mu < \epsilon$.
\end{theorem}

\begin{proof}
    Let $\{ \phi_n \}$ be as in the second assertion of \refthm{approximate_by_simple_functions}.
    Since $|\phi_n - f| \to 0$ pointwise and $|\phi_n - f| \le 2 |f|$ for all $n$, then $\int |\phi_n - f| < \epsilon$ for $n$ sufficiently large by \refthm{dominated_convergence}.

    If $\phi_n = \sum_{j=1}^{N} a_j \chi_{E_j}$ where $E_j$ are $E_j$ are disjoint and $a_j$ are nonzero, we observe that 
    \begin{align}
        \mu(E_j) = \frac{1}{|a_j|} \int_{E_j} |\phi_n| \le \frac{1}{|a_j|} \int_{E_j} |f| < \infty.
    \end{align}
    Thus if $\mu$ is a Lebesgue-Stieltjes measure on $\R$, then by \refprop{finite_open_interval}, we can approximate $E_j$ by a finite union of open intervals $I_{j,k}$ and 
    \begin{align}
        \int \left| \chi_{E_j} - \sum_{k=1}^{K_j} \chi_{I_{j,k}} \right| = \mu \left( E_j \triangle (\bigcup_{k=1}^{K_j} I_{j,k}) \right) < \epsilon.
    \end{align}
    Let us denote $\psi_n = \sum_{j=1}^{N} \chi_{\bigcup_{k=1}^{K_j} I_{j,k}} = \sum_{j=1}^{N} \sum_{k=1}^{K_j} a_j \chi_{I_{j,k}}$, then
    \begin{align}
        \int |\psi_n - f| & \le \int |\psi_n - \phi_n| + \int |\phi_n - f| \\
        & = \int \left| \sum_{j=1}^{N} a_j \left( \chi_{E_j} - \sum_{k=1}^{K} \chi_{I_{j,k}} \right) \right| + \epsilon \\
        & \le \sum_{j=1}^{N} |a_j| \int \left| \chi_{E_j} - \sum_{k=1}^{K_j} \chi_{I_{j,k}} \right| + \epsilon \\
        & \le \epsilon \left(1+ \sum_{j=1}^{N} |a_j| \right) = \epsilon'.
    \end{align}
    Thus for any $\epsilon'$, we have an integrable simple function $\psi_n$ with finite unions of open intervals such that $\int |\psi_n - f| < \epsilon'$.
    
    Finally, if $I_{k} = (a, b)$, we can approximate $\chi_{I_k}$ in the $L^1$ metric by continuous functions that vanish outside $(a, b)$.
    For example, given $\epsilon > 0$, take $g_k$ to be a continuous function that equals $0$ on $(-\infty, a]$ and $[b, \infty)$, equals $1$ on $[a+\epsilon, b-\epsilon]$, and is linear on $[a, a+\epsilon]$ and $[b-\epsilon, b]$.
    Then $\int |\chi_{I_k} - g| < 2 \epsilon$.
    By replacing $\chi_{I_k}$ in the preceding assertion with $g_k$, we obtain a continuous function $g$ that vanishes outside a bounded interval such that $\int |f - g| \dd \mu < \epsilon$.
\end{proof}

The first assertion states that the integrable simple functions are dense in $L^1$ in the $L^1$ metric.

The next theorem gives a criterion for the validity of interchanging a limit or a derivative with an integral. 

\begin{theorem}
    Suppose that $f: X \times [a, b] \to \C$ with $-\infty < a < b < \infty$ and that $f(\cdot, t): X \to \C$ is integrable for each $t \in [a, b]$.
    Let $F(t) = \int_X f(x,t) \dd \mu(x)$.
    \begin{enumerate}
        \item Suppose that there exists $g\in L^1(\mu)$ such that $|f(x,t)| \le g(x)$ for all $x, t$. If $\lim_{t \to t_0} f(x, t) = f(x, t_0)$ for every $x$, then $\lim_{t \to t_0} F(t) = F(t_0)$; in particular, if $f(x, \cdot)$ is continuous for each $x$, $F$ is continuous.
        \item Suppose that $\pp f / \pp t$ exists and there is an integrable function $g \in L^1(\mu)$ such that $|(\pp f / \pp t)(x, t)| \le g(x)$ for all $x, t$. Then $F$ is differentiable and $F'(x) = \int (\pp f / \pp t)(x,t) \dd \mu(x)$.
    \end{enumerate} 
\end{theorem}

\begin{proof}
    For the first part, let $f_n(x) = f(x, t_n)$ where $\{ t_n \}$ is any sequence in $[a, b]$ converging to $t_0$.
    Then ${f_n}$ is a sequence in $L^1$ as $f(\cdot, t): X \to \C$ is integrable for each $t \in [a, b]$.
    Additionally, we have $f_0(x) = f(x, t_0)$.
    If $\lim_{t \to t_0} f(x,t) = f(x, t_0)$ for every $x$ then $f_n \to f_0$.
    And the existence of $g$ shows that $|f_n| \le g$ for all $n$.
    Then by \refthm{dominated_convergence}, $f_0 \in L^1$ and $\int f_0 = \lim_{n \to \infty} \int f_n$ where $\int f_0 = \int_{X} f(x, t_0) \dd \mu(x) = F(t_0)$ and $\int f_n = \int_{X} f(x, t_n) \dd \mu(x) = F(t_n)$.
    Thus $\lim_{t \to t_0} F(t) = F(t_0)$.

    For the second part, observe that $(\pp f / \pp t)(x,t_0) = \lim_{n \to \infty} h_n(x)$ where $h_n(x) = \frac{f(x, t_n) - f(x, t_0)}{t_n - t_0}$.
    Again, $\{ t_n \}$ is any sequence in $[a, b]$ converging to $t_0$.
    It follows that $\pp f / \pp t$ is measurable\sidenote{Why measurable? Since $f$ is integrable and hence measurable for each $t$. Then its linear combination $h_n$ is measurable and its limit is measurable by \refcorollary{lim_measurable}.}.
    And by the Mean Value Theorem\sidenote{If $f(x)$ is continuous on the closed interval $[a,b]$ and differentiable on the open interval $(a,b)$, then there is a number $c$ such that $a < c < b$ and $f'(c) = \frac{f(b) - f(a)}{b-a}$.}, $|h_n(x)| \le \sup_{t \in [a, b]} |(\pp f / \pp t)(x, t)| \le g(x)$.
    Again, apply \refthm{dominated_convergence} to give
    \begin{align}
        F'(t_0) &= \lim_{n \to \infty} \frac{F(t_n) - F(t_0)}{t_n - t_0} \\
        &= \lim_{n \to \infty} \frac{\int_X f(x,t_n) \dd \mu(x) - \int_X f(x,t_0) \dd \mu(x)}{t_n - t_0} \\
        &= \lim_{n \to \infty} \int h_n(x) \dd \mu(x) \\
        &= \int \lim_{n \to \infty} h_n(x) \dd \mu(x) \\
        &= \int (\pp f / \pp t)(x,t) \dd \mu(x)
    \end{align}
\end{proof}

\section{Modes of convergence}

If $\{ f_n \}$ is a sequence of complex-valued functions on a set $X$, the statement ``$f_n \to f$ as $n \to \infty$'' can be taken in many different senses (\eg, pointwise or uniform convergence).
If $X$ is a measure space, one can also speak of almost everywhere convergence or convergence in $L^1$.
Of course, uniform convergence implies pointwise convergence, which in turn implies almost everywhere convergence (and not conversely, in general), but these modes of convergence do not imply $L^1$ convergence or vice versa. 

\begin{definition}[Cauchy in measure]
    \labdef{Cauchy_in_measure}
    A sequence $\{ f_n \}$ of measurable complex-valued functions on $(X, \mathcal{M}, \mu)$ is Cauchy in measure if for every $\epsilon$, then $\mu(\{ x: |f_n(x) - f_m(x)| \ge \epsilon \}) \to 0$ as $n, m \to \infty$.
\end{definition}

\begin{definition}[Convergence in measure]
    \labdef{convergence_in_measure}
    A sequence $\{ f_n \}$ of measurable complex-valued functions on $(X, \mathcal{M}, \mu)$ converges in measure to $f$ if for every $\epsilon$, then $\mu(\{ x: |f_n(x) - f(x)| \ge \epsilon \}) \to 0$ as $n \to \infty$.
\end{definition}

$f_n \to f$ in measure iff for every $\epsilon > 0$ there exists $N \in \N$ such that $\mu(\{ x: |f_n(x) - f(x)| \ge \epsilon \}) < \epsilon$ for $n \ge N$.

\begin{example}
    \labexample{convergence}
    We will examine the following examples:
    \begin{enumerate}
        \item $f_n = n^{-1} \chi_{(0, n)}$
        \item $f_n = \chi_{(n, n+1)}$ 
        \item $f_n = n \chi_{[0, 1/n]}$
        \item $f_n = \chi_{[j/2^k, (j+1)/2^k]}$ where $n = 2^k + j$ with $0 \le j < 2^k$. \eg, $f_1 = \chi_{[0, 1]}$, $f_2 = \chi_{[0, 1/2]}$, $f_3 = \chi_{[1/2, 1]}$, $f_4 = \chi_{[0, 1/4]}$, $f_5 = \chi_{[1/4, 1/2]}$, $f_6 = \chi_{[1/2, 3/4]}$, $f_7 = \chi_{[3/4, 1]}$, \etc
    \end{enumerate}
\end{example}

In 1, 2, and 3, $f_n \to 0$ uniformly, pointwise, and almost everywhere, respectively, but not in $L^1$ (in fact $\int |f_n| = 1$ for all $n$).
In 4, $f_n \to 0$ in $L^1$ since $\int |f_n| = 2^{-k}$ for $2^k \le n < 2^{k+1}$, but $f_n$ exhibits an oscillating manner for every $x \in [0, 1]$ and does converge for any $x \in [0, 1]$ since there are infinitely many $n$ for which $f_n(x) = 0$ and infinitely many for which $f_n(x) = 1$.

On the other hand, if $f_n \to f$ almost everywhere and $|f_n| \le g \in L^1$ for all $n$, then $f_n \to f$ in $L^1$.
As you can see, 1, 2, and 3 violate $|f_n| \le g \in L^1$ for all $n$.


\begin{proposition}
    \labprop{convergence_in_L1_implies_in_measure}
    If $f_n \to f$ in $L^1$, then $f_n \to f$ in measure.
\end{proposition}

\begin{proof}
    Let $E_{n,\epsilon} = \{ x: |f_n(x) - f(x)| \ge \epsilon \}$.
    Then
    \begin{align}
        \int |f_n - f| \ge \int_{E_{n,\epsilon}} |f_n - f| \ge \epsilon \mu(E_{n,\epsilon}).
    \end{align}
    So, $\mu(E_{n,\epsilon}) \le \epsilon^{-1} \int |f_n - f| \to 0$ as $n \to \infty$.
\end{proof}

\begin{proposition}
    \labprop{convergence_in_measure_implies_Cauchy_in_measure}
    If $f_n \to f$ in measure, then $\{ f_n \}$ is Cauchy in measure. 
\end{proposition}

\begin{proof}
    If $\{ f_n \}$ converges in measure to $f$ for every $\epsilon$, then $\mu(\{ x: |f_n(x) - f(x)| \ge \epsilon \}) \to 0$ as $n \to \infty$.
    Since $|f_n(x) - f_m(x)| \ge \epsilon$ implies at least one of $|f_n(x) - f(x)| \ge \epsilon'$ and $|f_m(x) - f(x)| \ge \epsilon - \epsilon'$ with $0 < \epsilon' < \epsilon$ must hold, 
    \begin{align}
        \{ x: |f_n(x) - f_m(x)| \ge \epsilon \} & \subset \{ x: |f_n(x) - f(x)| \ge \epsilon' \} \\
        & \cup \{ x: |f_m(x) - f(x)| \ge \epsilon - \epsilon' \}. \nonumber
    \end{align}
    Consequently, for every $\epsilon$
    \begin{align}
        \mu(\{ x: |f_n(x) - f_m(x)| \ge \epsilon \}) & \le \mu(\{ x: |f_n(x) - f(x)| \ge \epsilon' \}) \\
        & + \mu(\{ x: |f_m(x) - f(x)| \ge \epsilon - \epsilon' \}) \to 0, \nonumber
    \end{align}
    as $n, m \to \infty$.
    Therefore, $\{ f_n \}$ is Cauchy in measure.
\end{proof}

\begin{theorem}
    Suppose that $\{ f_n \}$ is Cauchy in measure.
    Then there is a measurable function $f$ such that $f_n \to f$ in measure, and there is a subsequence $\{ f_{n_j} \}$ that converges to $f$ almost everywhere.
    Moreover, if also $f_n \to g$ in measure, then $g = f$ almost everywhere.
\end{theorem}

\begin{proof}
    
\end{proof}

\begin{corollary}
    \labcorollary{convergence_in_L1_implies_subsequence_convergence_almost_everywhere}
    If $f_n \to f$ in $L^1$, there is a subsequence $\{ f_{n_j} \}$ such that $f_{n_j} \to f$ almost everywhere.
\end{corollary}

One are frequently attempted to show that convergence in L1 implies convergence almost everywhere.
However, this is wrong by 4 in \refexample{convergence}.

\begin{theorem}[Egoroff's Theorem]
    \labthm{Egoroff}
    Suppose that $\mu(X) < \infty$, and $\{ f_n \}$ and $f$ are measurable complex-valued functions on $X$ such that $f_n \to f$ almost everywhere.
    Then for every $\epsilon > 0$, there exists $E \subset X$ such that $\mu(E) < \epsilon$ and $f_n \to f$ uniformly on $E^c$.
\end{theorem}

\begin{proof}
    Without loss of generality, we may assume that $f_n \to f$ everywhere on $X$. 
    For $k, n \in \N$, let $E_n(k) = \bigcup_{m=n}^{\infty} \{ |f_m(x) - f(x)| \ge k^{-1} \}$.
    Then for fixed $k$, $E_n(k)$ decreases and $n$ increases, and $\bigcap_{n=1}^{\infty} E_n(k) = \emptyset$, so since $\mu(E_1(k)) \le \mu(X) < \infty$, we can conclude that $\mu(E_n(K)) \to 0$ as $n \to \infty$ according to \refthm{properties_measure}.
    Given $\epsilon > 0$ and $k \in \N$, we can choose $n_k$ so large that $\mu(E_{n_k}(k)) < \epsilon 2^{-k}$.
    Let $E = \bigcup_{k=1}^{\infty} E_{n_k}(k)$ and then $\mu(E) < \epsilon$ and $|f_n(x) - f(x)| < k^{-1}$ for $n > n_k$ and $x \notin E$.
    Thus $f_n \to f$ uniformly on $E^c$.
\end{proof}

\begin{remark}
    The requirement $\mu(X) < \infty$ in Egoroff's Theorem (\refthm{Egoroff}) is necessary.
\end{remark}

Let $X = [0, \infty)$ and $f_n = \chi_{(n, \infty)}$.
$f_n \to 0$ pointwise and hence almost everywhere.
However, $f_n$ does not converge almost uniformly.

Suppose $f_n$ converges to $0$ almost uniformly.
Then for any $\epsilon > 0$, there exists $E$ such that $\mu(E) < \epsilon$ and $f_n \to f$ uniformly on $E^c$.
This suggests there exists $N \in \N$ such that $E^c \cap (n, \infty) = \emptyset$ for all $n \ge N$.
However, this requires $E \supset (n, \infty)$ and hence $\mu(E) = \infty$ which contradicts $\mu(E) < \epsilon$.


The type of convergence involved in the conclusion of \refthm{Egoroff} is sometimes called almost uniform convergence. 

\begin{definition}[Almost Uniform Convergence]
    A sequence of functions $\{ f_n \}$ is almost uniform convergent, if there exists $E \subset X$ such that $\mu(E) < \epsilon$ and $f_n \to f$ uniformly on $E^c$.
\end{definition}

An uniform convergence implies almost uniform convergence because that $\mu(X^c) = 0$ and $f_n \to f$ uniformly on $X$.

\begin{proposition}
    If $f_n \to f$ almost uniformly, then $f_n \to f$ almost everywhere and in measure.
\end{proposition}

\begin{proof}
    We first recall that $f_n \to f$ almost uniformly means that there exists a sequence $\{ E_n \} \subset \mathcal{M}$ such that $\mu(E_n^c) < \frac{1}{n}$ and $f_n \to f$ uniformly on $E_n$.
    If we define $E = \bigcup_{n} E_n$, then $\mu(E^c) \le \liminf_{n} \mu(E_n^c) = 0$.
    Hence $f_n \to f$ almost everywhere.

    Now to show that $f_n \to f$ in measure.
    For all $\epsilon > 0$ and $\delta > 0$, since $f_n \to f$ almost uniformly, there exists $E \in \mathcal{M}$ and $N \in \N$ such that for all $n \ge N$, $|f_n(x) - f(x)| < \epsilon$ holds for all $x \in E$ and $\mu(E^c) < \delta$.
    Therefore given arbitrary $\epsilon$ and $\delta$, $\mu(\{ x: |f_n(x) - f(x)| \ge \epsilon \}) \le \mu(E^c) < \delta$ for all $n \ge N$, which suggests $f_n \to f$ in measure.
\end{proof}

\begin{table*}[h!]
    \caption{Examples of modes of convergence}
    \begin{tabular}{lcccccc}
        \toprule 
                               & \multicolumn{6}{c}{Modes of convergence} \\
        \cmidrule(lr){2-7}
                               &         &           & almost     &          & in      & almost \\
        $f_n$                  & uniform & pointwise & everywhere & in $L^1$ & measure & uniform \\
        \midrule
        $n^{-1} \chi_{(0, n)}$ & Y       & Y         & Y          & N        & Y       & Y \\
        $\chi_{(n, n+1)}$      & N       & Y         & Y          & N        & N       & X \\
        $n \chi_{[0, 1/n]}$    & N       & N         & Y          & N        & Y       & Y \\
        $\chi_{[j/2^k, (j+1)/2^k]}$ & N  & N         & N          & Y        & Y       & N \\
        \bottomrule
    \end{tabular}
\end{table*}

\begin{theorem}[Lusin's Theorem]
    \labthm{Lusin}
    If $f: [a, b] \to \C$ is Lebesgue measurable and $\epsilon > 0$, there is a compact set $K \subset [a, b]$ such that $\mu(K^c) < \epsilon$ and $f|K$ is continuous.
\end{theorem}

\begin{proof}
    By \refthm{approximate_in_L1}, there is a sequence of continuous functions $\{ f_n \}$ such that $f_n \to f$ in $L^1$.
    By \refprop{convergence_in_L1_implies_in_measure}, $f_n \to f$ in measure, and by \refcorollary{convergence_in_L1_implies_subsequence_convergence_almost_everywhere}, a subsequence $\{ f_{n_j} \}$ exists such that $f_{n_j} \to f$ almost everywhere.
    And by Egoroff's Theorem (\refthm{Egoroff}), for every $\epsilon > 0$, there is $E \subset [a, b]$ such that $\mu(E^c) < \frac{\epsilon}{2}$ and $f_{n_j} \to f$ uniformly on $E$.
    So $f|E$ is continuous\sidenote{This is because $f_{n_j} \to f$ uniformly and $f_{n_j}$ are continuous. Say $g_j \to g$ uniformly and $g_j$ are continuous. Then for every $x$, for any $\epsilon > 0$, there exists a $\delta > 0$ such that for all $|y - x| \le \delta$, $|g(y) - g(x)| \le |g_n(y) - g(y)| + |g_n(x) - g(x)| + |g_n(y) - g_n(x)| < \epsilon$.}.
    By \refthm{measure_open_compact}, since $E \in \mathcal{M}_{\mu}$, $\mu(E) = \sup \left\{ \mu(K): K \subset E \text{ and } K \text{ is compact} \right\}$.
    Thus there exists a compact set $K \subset E$ such that $\mu(E \setminus K) < \frac{\epsilon}{2}$.
    Then $\mu(K^c) = \mu(E^c) - \mu(E \setminus K) < \epsilon$ and $f|K$ is continuous.
\end{proof}

\section{Product measures}

Let $(X, \mathcal{M}, \mu)$ and  $(Y, \mathcal{N}, \nu)$ be measure spaces. 
We have already discussed the product $\sigma$-algebra $\mathcal{M} \otimes \mathcal{N}$ on $X \times Y$; 
we now construct a measure on $\mathcal{M} \otimes \mathcal{N}$ that is, in an obvious sense, the product of $\mu$ and $\nu$.


We return to the case of two measure spaces $(X, \mathcal{M}, \mu)$ and  $(Y, \mathcal{N}, \nu)$.
If $E \subset X \times Y$, for $x \in X$ and $y \in Y$, we define the $x$-section $E_x$ and the $y$-section $E^y$ of $E$ by
\begin{align}
    E_x = \{ y \in Y: (x, y) \in E \},
    E^y = \{ x \in X: (x, y) \in E \}.
\end{align}
Also, if $f$ is a function on $X \times Y$ we define the $x$-section $f_x$ and the $y$-section $f^y$ of $f$ by $f_x(y) = f^y(x) = f(x, y)$.

Thus, for example, $(\chi_{E})_{x} = \chi_{E_{x}}$ and $(\chi_{E})^{y} = \chi_{E^{y}}$.

\begin{proposition}

    \begin{enumerate}
        \item If $E \in \mathcal{M} \times \mathcal{N}$, then $E_x \in \mathcal{N}$ for all $x \in X$ and $E^y \in \mathcal{M}$ for all $y \in Y$.
        \item If $f$ is $\mathcal{M} \otimes \mathcal{N}$-measurable, then $f_x$ is $\mathcal{N}$-measurable for all $x \in X$ and $f^y$ is $\mathcal{M}$-measurable for all $y \in Y$. 
    \end{enumerate}
\end{proposition}

\begin{proof}
    Let $\mathcal{R}$ be the collection of all subsets $E$ of $X \times Y$ such that $E \in \mathcal{N}$ for all $x$ and $Y \in \mathcal{M}$ for all $y$. 
    Then $\mathcal{R}$ contains all rectangles because
    \begin{align}
        (A \times B)_x = \begin{cases}
            B, & \text{ if } x \in A, \\
            \emptyset, & \text{ otherwise}.
        \end{cases}
    \end{align}
    Since $(\bigcup_{j=1}^{\infty} E_j)_x = \bigcup_{j=1}^{\infty} (E_j)_x$ and $(E^c)_x = (E_x)^c$, and likewise for $y$-sections.
    $\mathcal{R}$ is closed under countable unions and complements, so $\mathcal{R}$ is a $\sigma$-algebra.
    Therefore $\mathcal{R} \supset \mathcal{M} \otimes \mathcal{N}$ which proves 1.
    2 follows from 1 because
    \begin{align}
        (f_x)^{-1}(B) = (f^{-1}(B))_x,
        (f^y)^{-1}(B) = (f^{-1}(B))^y.
    \end{align}
\end{proof}

\begin{definition}[Monotone Class]
    \labdef{monotone_class}
    A monotone class on a space $X$ is a subset $\mathcal{C}$ of $\mathcal{P}(X)$ that is closed under countable increasing unions and countable decreasing intersections.
    For any $\mathcal{E} \subset \mathcal{P}(X)$, there is a unique smallest monotone class containing $\mathcal{E}$, called the monotone class generated by $\mathcal{E}$.
\end{definition}

By definition, every $\sigma$-algebra is a monotone class.
Since the intersection of any family of monotone classes is a monotone class, there is a unique smallest monotone class containing $\mathcal{E}$, that is the intersection of all monotone class containing $\mathcal{E}$.

\begin{lemma}[The Monotone Class Lemma]
    \lablemma{monotone_class_lemma}
    If $\mathcal{A}$ is an algebra of subsets of $X$, then the monotone class $\mathcal{C}$ generated by $\mathcal{A}$ coincides with the $\sigma$-algebra $\mathcal{M}$ generated by $\mathcal{A}$
\end{lemma}

\begin{proof}
    Since $\mathcal{M}$ is a monotone class, we have $\mathcal{C} \subset \mathcal{M}$;
    and if we can show that $\mathcal{C}$ is a $\sigma$-algebra, we will have $\mathcal{C} \supset \mathcal{M}$.
    To this end, for $E \in \mathcal{C}$, let us define
    \begin{align}
        \mathcal{C}(E) = \{ F \in \mathcal{C}: E \setminus F, F \setminus E, \text{ and } E \cap F \text{ are in } \mathcal{C} \}.
    \end{align}
    Clearly, $\emptyset$ and $E$ are in $\mathcal{C}(E)$, and $E \in \mathcal{C}(F)$ iff $F \in \mathcal{C}(E)$.
    Also, it is easy to check that $\mathcal{C}(E)$ is a monotone class.
    If $E \in \mathcal{A}$, then $F \in \mathcal{C}(E)$ for all $F \in \mathcal{A}$ because $\mathcal{A}$ is an algebra;
    that is, $\mathcal{A} \subset \mathcal{C}(E)$, and hence $\mathcal{C} \subset \mathcal{C}(E)$.
    Therefore, if $F \in \mathcal{C}$, then $F \in \mathcal{C}(E)$ for all $E \in \mathcal{A}$.
    But this means that $E \in \mathcal{C}(F)$ for all $E \in \mathcal{A}$, so that $\mathcal{A} \subset \mathcal{C}(F)$ and hence $\mathcal{C} \subset \mathcal{C}(F)$.
    Conclusion: If $E, F \in \mathcal{C}$, then $E \setminus F$ and $E \cap F$ are in $\mathcal{C}$.
    Since $X \in \mathcal{A} \subset \mathcal{C}$, $\mathcal{C}$ is therefore an algebra.
    But then if $\{ E_j \} \subset \mathcal{C}$, we have $\bigcup_{j=1}^{n} E_j \in \mathcal{C}$ for all $n$, and since $\mathcal{C}$ is closed under countable increasing unions, it follows that $\bigcup_{j=1}^{\infty} E_j \in \mathcal{C}$.
    In short, $\mathcal{C}$ is a $\sigma$-algebra, and we are done.
\end{proof}

We now come to the main results of this section, which relate integrals on $X \times Y$ to integrals on $X$ and $Y$.

\begin{theorem}
    \labthm{}
    Suppose that $(X, \mathcal{M}, \mu)$ and  $(Y, \mathcal{N}, \nu)$ are $\sigma$-finite measure spaces.
    If $E \in \mathcal{M} \otimes \mathcal{N}$, then the functions $x \mapsto \nu(E_x)$ and $y \mapsto \mu(E^y)$ are measurable on $X$ and $Y$, respectively, and
    \begin{align}
        \mu \times \nu(E) = \int \nu(E_x) \dd \mu(x) = \int \mu(E^y) \dd \nu(y).
    \end{align}
\end{theorem}

\begin{proof}
    First, suppose that $\mu$ and $\nu$ are finite, and let $\mathcal{C}$ be the set of all $E \in \mathcal{M} \otimes \mathcal{N}$ for which the conclusions of the theorem are true.
    If $E = A \times B$ is a rectangle, then $\nu(E_x) = \chi_{A}(x) \nu(B)$ and $\mu(E^y) = \mu(A) \chi_{B}(y)$, so clearly $E \in \mathcal{C}$.
    By additivity, it follows that finite disjoint unions of rectangles are in $\mathcal{C}$, so by \reflemma{monotone_class_lemma}, it will suffice to show that $\mathcal{C}$ is a monotone class.
    If $\{ E_n \}$ is an increasing sequence in $\mathcal{C}$ and $E = \bigcup_{n=1}^{\infty} E_n$, then the functions $f_n(y) = \mu((E_n)^y)$ are measurable and increase pointwise to $f(y) = \mu(E^y)$.
    Hence $f$ is measurable, and by \refthm{monotone_convergence_theorem}, 
    \begin{align}
        \int \mu(E^y) \dd \nu(y) = \lim \int \mu((E_n)^y) \dd \nu(y) = \lim \mu \times \nu (E_n) = \mu \times \nu(E).
    \end{align}
    Likewise $\mu \times \nu(E) = \int \nu(E_x) \dd \mu(x)$, so $E \in \mathcal{C}$.
    Similarly, if $\{ E_n \}$ is a decreasing sequence in $\mathcal{C}$ and $\bigcap E_n$, the function $y \mapsto \mu((E_1)^y)$ is in $L^1(\nu)$ because $\mu((E_1)^y) \le \mu(X) < \infty$ and $\nu(Y) < \infty$, so \refthm{dominated_convergence} can be applied to show that $E \in \mathcal{C}$.
    Thus $\mathcal{C}$ is a monotone class, and the proof is complete for the case of finite measure spaces.

    Finally, if $\mu$ and $\nu$ are $\sigma$-finite, we can write $X \times Y$ as the union of an increasing sequence $\{ X_j \times Y_j \}$ of rectangles of finite measure.
    If $E \in \mathcal{M} \otimes \mathcal{N}$, the preceding argument applies to $E \cap (X_j \times Y_j)$ for each $j$ to give
    \begin{align}
        \mu \times \nu(E \cap (X_j \times Y_j)) = \int \chi_{X_j}(x) \nu(E_x \cap Y_j) \dd \mu(x) = \int \chi_{Y_j}(y) \mu(E^y \cap X_j) \dd \nu(y),
    \end{align}
    and a final application of \refthm{monotone_convergence_theorem} then yields the desired result.
\end{proof}

\begin{theorem}[The Fubini-Tonelli Theorem]
    \labthm{Fubini_Tonelli}
    Suppose that $(X, \mathcal{M}, \mu)$ and $(Y, \mathcal{N}, \nu)$ are $\sigma$-finite measure spaces.
    \begin{enumerate}
        \item (Tonelli) If $f \in L^+(X \times Y)$, then the functions $g(x) = \int f_x \dd \nu$ and $h(y) = \int f^y \dd \mu$ are in $L^+(X)$ and $L^+(Y)$, respectively, and
        \begin{align}
            \int f \dd (\mu \times \nu) &= \int \left[ \int f(x, y) \dd \nu(y) \right] \dd \mu(x) \labeq{Tonelli} \\
            &= \int \left[ \int f(x, y) \dd \mu(x) \right] \dd \nu(y). \nonumber
        \end{align}
        \item (Fubini) If $f \in L^1(\mu \times \nu)$, then $f_x \in L^1(\nu)$ for almost everywhere $x \in X$, $f^y \in L^1(\mu)$ for almost everywhere $y \in Y$, the almost everywhere defined functions $g(x) = \int f_x \dd \nu$ and $h(y) = \int f^y \dd \mu$ are in $L^1(\mu)$ and $L^1(\nu)$, respectively, and \refeq{Tonelli} holds.
    \end{enumerate}
\end{theorem}

\begin{proof}
    
\end{proof}

\begin{remark}
    We shall usually omit the brackets in the iterated integrals in \refeq{Tonelli}, thus:
    \begin{align}
        \int \left[ \int f(x, y) \dd \mu(x) \right] \dd \nu(y) = \iint f(x, y) \dd \mu(x) \dd \nu(y) = \iint f \dd \mu \dd \nu.
    \end{align}
\end{remark}

\begin{remark}
    The hypothesis of $\sigma$-finiteness is necessary.
\end{remark}

\begin{remark}
    The hypothesis that $f \in L^+(X \times Y)$ or $f \in L^1(\mu \times \nu)$ is necessary, 
\end{remark}

\begin{remark}
    The Fubini and Tonelli theorems (\refthm{Fubini_Tonelli}) are frequently used in tandem.
    Typically one wishes to reverse the order of integration in a double integral $\iint f \dd \mu \dd \nu$.
\end{remark}

First, one should verify that $\int |f| \dd (\mu \times \nu) < \infty$ by using Tonelli's theorem to evaluate this integral as an iterated integral; then one applies Fubini's theorem to conclude that $\iint f \dd \mu \dd \nu = \iint f \dd \nu \dd \mu$.

\begin{theorem}[The Fubini-Tonelli Theorem for complete measures]
    \labthm{Fubini_Tonelli_complete_measure}
    Let $(X, \mathcal{M}, \mu)$ and $(Y, \mathcal{N}, \nu)$ be complete, $\sigma$-finite measure spaces, and let $(X \times Y, \mathcal{L}, \lambda)$ be the completion of $(X \times Y, \mathcal{M} \otimes \mathcal{N}, \mu \times \nu)$.
    if $f$ is $\mathcal{L}$-measurable and either (a) $f \ge 0$ or (b) $f \in L^1(\lambda)$, then $f_x$ is $\mathcal{N}$-measurable for almost everywhere $x$ and $f^y$ is $\mathcal{M}$-measurable for almost every $y$ and in case (b) $f_x$ and $f^y$ are also integrable for almost everywhere $x$ and $y$.
    Moreover, $x \mapsto \int f_x \dd \nu$ and $y \mapsto \int f^y \dd \mu$ are measurable, and in case (b) also integrable, and 
    \begin{align}
        \int f \dd \lambda = \iint f(x, y) \dd \mu(x) \nu(y) = \iint f(x, y) \dd \nu(y) \dd \mu(x).
    \end{align}
\end{theorem}

\begin{proof}
    
\end{proof}

\section{The n-dimensional Lebesgue integral}

\begin{theorem}
    Suppose $E \in \mathcal{L}^n$.
    \begin{enumerate}
        \item $m(E) = \inf \{ m(U): U \supset E, U \text{ is open} \} = \sup \{ m(K): K \subset E, K \text{ is compact} \}$.
        \item $E = A_1 \cup N_1 = A_2 \setminus N_2$ where $A_1$ is an $F_\sigma$ set, $A_2$ is an $G_\delta$ set, and $m(N_1) = m(N_2) = 0$.
        \item If $m(E) < \infty$, for any $\epsilon > 0$ there is a finite collection $\{ R_j \}_{j=1}^{N}$ of disjoint rectangles whose sides are intervals such that $m(E \triangle \bigcup_{j=1}^{N} R_j) < \epsilon$.
    \end{enumerate}
\end{theorem}

\begin{proof}
    
\end{proof}

\refthm{measure_open_compact}, \refthm{differ_by_0_measure_set}, \refprop{finite_open_interval}.

\begin{theorem}
    If $f \in L^1(m)$ and $\epsilon > 0$, there is a simple function $\phi = \sum_{j=1}^{N} a_j \chi_{R_j}$, where each $R_j$ is a product of intervals, such that $\int |f - \phi| < \epsilon$, and there is a countinuous function $g$ that vanishes outside a bounded set such $\int |f-g| < \epsilon$. 
\end{theorem}

\begin{theorem}
    Lebesgue measure is translation-invariant.
    More precisely, for $a \in \R^n$ define $\tau_a: \R^n \to \R^n$ by $\tau_a(x) = x + a$.
    \begin{enumerate}
        \item If $E \in \mathcal{L}^n$, then $\tau_a (E) \in \mathcal{L}^n$ and $m(\tau_a(E)) = m(E)$.
        \item If $f: \R^n \to \C$ is Lebesgue measurable, then so is $f \circ \tau_a$. Moreover, if either $f \ge 0$ or $f \in L^1(m)$, then $\int (f \circ \tau_a) \dd m = \int f \dd m$.
    \end{enumerate}
\end{theorem}

\begin{lemma}
    If $U \subset \R^n$ is open, then $U = \underbar{A}(U)$.
    Moreover, $U$ is a countable union of cubes with disjoint interiors.
\end{lemma}

\begin{theorem}
    Suppose $T \in GL(n, \R)$.
    \begin{enumerate}
        \item If $f$ is a Lebesgue measurable function on $\R^n$, so is $f \circ T$. If $f \ge 0$ or $f \in L^1(m)$, then
        \begin{align}
            \int f(x) \dd x = |\det T| \int f \circ T(x) \dd x.
        \end{align}
        \item If $E \in \mathcal{L}^n$, then $T(E) \in \mathcal{L}^n$ and $m(T(E)) = |\det T| m(E)$.
    \end{enumerate}
\end{theorem}

\begin{corollary}
    Lebesgue measure is invariant under rotations.
\end{corollary}

\begin{definition}
    Let $G = (g_1, \dots, g_n)$ be a map from an open set $\Omega \subset \R^n$ into $\R^n$ whose components $g_j$ are of class $C^1$, \ie, have continuous first-order partial derivatives.
    We denote by $D_{x} G$ the linear map defined by the matrix $\left(\frac{\pp g_i}{\pp x_j}(x)\right)$ of partial derivatives at $x$.
    $G$ is called a $C^1$ diffeomorphism if $G$ is injective and $D_{x} G$ is invertible for all $x \in \Omega$.
\end{definition}

In this case, the inverse function theorem\sidenote{The inverse function theorem states: TODO.} guarantees that $G^{-1}: G(\Omega) \to \Omega$ is also a $C^1$ diffeomorphism and that $D_{x}(G^{-1}) = [D_{G^{-1}(x)} G]^{-1}$ for all $x \in G(\Omega)$.

\begin{theorem}
    Suppose that $\Omega$ is an open set in $\R^n$ and $G: \Omega \to \R^n$ is a $C^1$ diffeomorphism.
    \begin{enumerate}
        \item If $f$ is Lebesgue measurable on $G(\Omega)$, then $f \circ G$ is Lebesgue measurable on $\Omega$. If $f \ge 0$ or $f \in L^1(G(\Omega), m)$, then
        \begin{align}
            \int _{G(\Omega)} f(x) \dd x = \int_{\Omega} f \circ G (x) |\det D_{x} G| \dd x.
        \end{align}
        \item If $E \subset \Omega$ and $E \in \mathcal{L}^n$, then $G(E) \in \mathcal{L}^n$ and $m(G(E)) = \int_{E} |\det D_{x} G| \dd x$.
    \end{enumerate}
\end{theorem}

\section{Integration in polar coordinates}

The most important nonlinear coordinate systems in $\R^2$ and $\R^3$ are polar coordinates ($x = r \cos \theta, y = r \sin \theta$) and spherical coordinates ($x = r \sin \phi \cos \theta, y = r \sin \phi \sin \theta, z = r \cos \phi$).

We denote the unit sphere $\{ x \in \R^n: |x| = 1 \}$ by $S^{n-1}$.

The map $\Phi (x) =(r, x')$ is a continuous bijection from $\R^n \setminus \{0\}$ to $(0, \infty) \times S^{n-1}$ whose continuous inverse is $\Phi^{-1}(r, x') = rx'$.
We denote by $m_{*}$ the Borel measure on $(0, \infty) \times S^{n-1}$ induced by $\Phi$ from Lebesgue measure on $\R^n$, that is $m_{*}(E) = m(\Phi^{-1}(E))$.
Moreover, we define $\rho = \rho_n$ on $(0, \infty)$ by $\rho(E) = \int_E r^{n-1} \dd r$.

\begin{theorem}
    There is a unique Borel measure $\sigma = \sigma_{n-1}$ on $S^{n-1}$ such that $m_{*} = \rho \times \sigma$.
    If $f$ is Borel measurable on $\R^n$ and $f \ge 0$ or $f \in L^1(m)$, then
    \begin{align}
        \int_{\R^n} f(x) \dd x = \int_{0}^{\infty} \int_{S^{n-1}} f(rx') r^{n-1} \dd \sigma(x') \dd r.
    \end{align}
\end{theorem}

\begin{corollary}
    If $f$ is a measurable function on $\R^n$, nonnegative or integrable, such that $f(x) = g(|x|)$ for some function $g$ on $(0, \infty)$, then
    \begin{align}
        \int f(x) \dd x = \sigma(S^{n-1}) \int_{0}^{\infty} g(r) r^{n-1} \dd r.
    \end{align}
\end{corollary}

\begin{corollary}
    Let $c$ and $C$ denote positive constants, and let $B = \{x \in \R^n: |x| < c \}$.
    Suppose that $f$ is a measurable function on $\R^n$.
    \begin{enumerate}
        \item If $|f(x)| \le C|x|^{-a}$ on $B$ for some $a < n$, then $f \in L^1(B)$. However, if $|f(x)| \ge C|x|^{-n}$ on $B$, then $f \notin L^1(B)$.
        \item If $|f(x)| \le C|x|^{-a}$ on $B$ for some $a > n$, then $f \in L^1(B^c)$. However, if $|f(x)| \ge C|x|^{-n}$ on $B^c$, then $f \notin L^1(B^c)$.
    \end{enumerate}
\end{corollary}

\begin{proposition}
    If $a > 0$, 
    \begin{align}
        \int_{\R^n} \exp(-a |x|^2) \dd x = \left(\frac{\pi}{a}\right)^{n/2}.
    \end{align}
\end{proposition}

\begin{proposition}
    \begin{align}
        \sigma(S^{n-1}) = \frac{2 \pi^{n/2}}{\Gamma(n/2)}.
    \end{align}
\end{proposition}

\begin{corollary}
    If $B^n = \{x \in \R^n: |x| < 1 \}$, then 
    \begin{align}
        m(B^n) = \frac{\pi^{n/2}}{\Gamma(\frac{n}{2}+1)}.
    \end{align}
\end{corollary}

\begin{proposition}
    \begin{align}
        \Gamma(n + \frac{1}{2}) = (n - \frac{1}{2}) (n - \frac{3}{2}) \cdots (\frac{1}{2}) \sqrt{\pi}.
    \end{align}
\end{proposition}